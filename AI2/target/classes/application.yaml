spring:
  application:
    name: AI
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: deepseek-r1:1.5b

      client:
        name: ai-demo
        type: SYNC
        toolcallback:
          enabled: true

        request-timeout: 30000
        enabled: true
        sse:
          connections:
            serve1.url: https://mcp-09724909-442f-4b85.api-inference.modelscope.cn

    vectorstore:
      pgvector:
       initialize-schema: true
       index-type: HNSW
       distance-type: COSINE_DISTANCE
       dimensions: 1536
       max-document-batch-size: 10000 # Optional: Maximum number of documents per batch

server:
  port: 8000
milvus:
  host: 192.168.3.17
  port: 19530
logging:
  level:
    org.springframework.ai.chat.client.advisor: debug
    com.itheima.ai: debug

    
